分布式爬虫：
    概念：我们需要搭建一个分布式的集群，让其对一组资源进行分布联合爬取。
    作用：提升爬取数据的效率。

    如何实现分布式？
        1.安装一个scrapy-redis的组件, 原生的scarpy不可以实现分布式爬虫，必须要结合scrapy-redis组件。
        2.scrapy-redis组建的作用是什么？
            可以给原生的scrapy提供可以被共享的管道和调度器。
        3.实现流程
            创建一个工程
            创建一个CrawlSpider的爬虫文件。
            修改当前的爬虫文件：
                导包：from scrapy_redis.spiders import RedisCrawlSpider。
                将start_urls和allow_domains进行注释。
                添加一个新属性：redis_key = 'sun'，可以被共享的调度器队列的名称